# -*- coding: utf-8 -*-
"""nmf_embed.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1P5530OLYA0erdCI4gSnhNxw7PgEHn1XM
"""

import numpy as np
import pandas as pd

import random
import math

from surprise import NMF, Dataset, Reader

def find_missing_denote(Data):
  denote_features = []
  for ii in Data.columns:
    if 'denote' in ii:
      denote_features.append(ii)

  denote = Data[denote_features]
  denote = np.array(denote, dtype = float)
  denote = np.transpose(denote)

  denote = Data['denote']
  height = len(Data)
  num_days = np.ceil(height/(24*60))
  num_days = int(num_days)
  denote_pad = []

  for i in range(1,num_days+1):
    if i != num_days:
      idx_prev = (i-1)*60*24
      idx_curr = i*60*24
      indices = np.array(range(idx_prev, idx_curr))
      day_curr = np.take(denote, indices)
      if i == 1:
        denote_pad = day_curr
      elif i != 1:
        denote_pad = np.vstack((denote_pad, day_curr))

    elif i == num_days:
      idx_prev = (i-1)*60*24
      idx_curr = int(denote.size)
      indices = np.array(range(idx_prev, idx_curr))
      day_curr = np.take(denote, indices)
      miss = np.zeros(60*24*num_days - idx_curr)
      day_curr = np.hstack((day_curr, miss))
      denote_pad = np.vstack((denote_pad, day_curr))

  return denote_pad

################################################################################
# function pad_NMF -- apply padding to the sleep label data so that the NMF considers sleep data per day, rather than per hour
def pad_NMF(Data):
    slp_features = []
    for ii in Data.columns:
      if 'Label' in ii:
        slp_features.append(ii)

    slp = Data[slp_features]
    slp = np.array(slp, dtype = float)
    slp = np.transpose(slp)

    slp = Data['Label']
    height = len(Data)
    num_days = np.ceil(height/(24*60))
    num_days = int(num_days)
    slp_pad = []

    for i in range(1,num_days+1):
      if i != num_days:
        idx_prev = (i-1)*60*24
        idx_curr = i*60*24
        indices = np.array(range(idx_prev, idx_curr))
        day_curr = np.take(slp, indices)
        if i ==1:
          slp_pad = day_curr
        elif i != 1:
          slp_pad = np.vstack((slp_pad, day_curr))

      elif i == num_days:
        idx_prev = (i-1)*60*24
        idx_curr = np.int(slp.size)
        indices = np.array(range(idx_prev, idx_curr))
        day_curr = np.take(slp, indices)
        miss = np.zeros(60*24*num_days - idx_curr)
        day_curr = np.hstack((day_curr, miss))
        slp_pad = np.vstack((slp_pad, day_curr))

    return slp_pad

################################################################################
# sleep_NMF: Function to implement NMF to sleep labels
# Input: Data -- the imported data before separating them into Label, denote, and actigraphy
#        num_feat -- number of underlying features, i.e., the rank of the lower rank matrix represenataion
def sleep_NMF(pad_data, Data, num_feat=20):
  NMF_data = Data['Label']
  slp = pad_data

  # Extract denote features
  denote = find_missing_denote(Data)

  # Replace labels to avoid float division error
  R = pad_data
  l = len(R)
  h = int(R.size/l)
  for i in range(0,l):
    for j in range(0,h):
      if slp[i,j] == 1:
        R[i,j] = 2
      elif slp[i,j] == 0:
        R[i,j] = 1

      if denote[i,j] == 0:
        R[i,j] = np.nan

  # Set up for NMF
  df = pd.DataFrame(data=R, index=range(R.shape[0]), columns=range(R.shape[1]))
  df = pd.melt(df.reset_index(), id_vars='index', var_name='items', value_name='sleep').dropna(axis=0)
  reader = Reader(rating_scale=(1, 2))
  data = Dataset.load_from_df(df[['index', 'items', 'sleep']], reader)

  k = num_feat # number of feature components
  algo = NMF(n_factors=k) 
  trainset = data.build_full_trainset() 
  algo.fit(trainset)
  
  predictions = algo.test(trainset.build_testset()) # predict the known ratings
  R_hat = np.zeros_like(R)
  for uid, iid, true_r, est, _ in predictions:
      R_hat[uid, iid] = est

  predictions = algo.test(trainset.build_anti_testset()) # predict the unknown ratings
  for uid, iid, true_r, est, _ in predictions:
      R_hat[uid, iid] = est

  R_hat = R_hat - 1

  return R_hat
################################################################################
# A function to find the optimal number of underlying features
def find_opt_num_feat(pad_data, Data): 
  # Extract denote features

  denote = find_missing_denote(Data)  
  slp = pad_data

  # Replace labels to avoid float division error

  pred = slp
  pred[denote==0] = np.nan
  min_loss = 1000000000
  opt_num_feat = 0

  # Start for loop to find the optimal number of underlying features
  for iii in range(1,25):
    nmf = sleep_NMF(pad_data, Data, iii)
    diff = np.subtract(nmf[denote==1], pred[denote==1])
    diff = np.square(diff)
    loss = np.sum(diff)

    # print(loss)

    if loss <= min_loss:
      min_loss = loss
      opt_num_feat = iii

  return opt_num_feat


################################################################################